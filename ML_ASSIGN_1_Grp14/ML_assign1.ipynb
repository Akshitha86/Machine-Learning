{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_assign1.ipynb",
      "provenance": [],
      "history_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyhEORCfEbTg"
      },
      "source": [
        "class node:\n",
        "    '''\n",
        "    This is the main node class of the decision tree\n",
        "    This class contains the skeleton of the structure \n",
        "    of each node in the decision tree. \n",
        "    '''\n",
        "\n",
        "    def __init__(self, attr, val, mean, mse):\n",
        "        '''\n",
        "        This function is the constructor to initialize the \n",
        "        values in the node object.\n",
        "        Parameters\n",
        "        ----------\n",
        "        attr: [String] the decision attribute that has been selected \n",
        "                for this node on the basis of which the \n",
        "                children will be decided\n",
        "        val: [Float] the value of the selected attribute on the \n",
        "                basis which the splitting of the children \n",
        "                nodes will be decided for the current node\n",
        "        mean: [Float] mean of the attributes ( selected in the current \n",
        "                level ) of the training data, this will help in \n",
        "                making predictions at this node if it is a leaf\n",
        "        mse: [Float] mean squared error of the attributes ( selected in the \n",
        "                current level ) of the training data, this will help \n",
        "                in making decisions for pruning\n",
        "        '''\n",
        "        self.attr = attr\n",
        "        self.split = val\n",
        "        self.mse = mse\n",
        "        self.mean = mean\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "    def remove_children(self):\n",
        "        '''\n",
        "        This function is a helper function for the pruning step\n",
        "        the following function removes the children of the current node\n",
        "        '''\n",
        "        self.right = None\n",
        "        self.left = None\n",
        "        self.attr = 'y'\n",
        "\n",
        "    def restore(self, attr, left, right):\n",
        "        '''\n",
        "        This function will restore the  children nodes of the current \n",
        "        node during the pruning process if you decide not to remove \n",
        "        the cchildren of the current node \n",
        "        '''\n",
        "        self.attr = attr\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "    def count_node(self):\n",
        "        '''\n",
        "        This function is a helper funcction which is used to recursively \n",
        "        count the number of nodes in the tree rooted at the given node \n",
        "        '''\n",
        "        num_nodes = 1\n",
        "        if self.left != None:\n",
        "            num_nodes += self.left.count_node()\n",
        "        if self.right != None:\n",
        "            num_nodes += self.right.count_node()\n",
        "        return num_nodes\n",
        "\n",
        "    def prune(self, decision_tree_root, cur_error, X_valid):\n",
        "        '''\n",
        "        This function is the main pruning function. This function \n",
        "        will first recursively prune the children of the current node\n",
        "        then will decide whether to prune the correct node or not \n",
        "        '''\n",
        "        if self.left == None and self.right == None:\n",
        "            return 10**18\n",
        "        if self.left != None:\n",
        "            self.left.prune(decision_tree_root, cur_error, X_valid)\n",
        "        if self.right != None:\n",
        "            self.right.prune(decision_tree_root, cur_error, X_valid)\n",
        "\n",
        "        cur_error, _ = predict(decision_tree_root, X_valid)\n",
        "\n",
        "        # store the data of the children nodes in temporary variable\n",
        "        temp_left = self.left\n",
        "        temp_right = self.right\n",
        "        temp_attr = self.attr\n",
        "        self.remove_children()\n",
        "\n",
        "        # calculate the error on the new decision tree\n",
        "        err, _ = predict(decision_tree_root, X_valid)\n",
        "\n",
        "        # print(err, cur_error)\n",
        "\n",
        "        # if the error on the new decision tree increases then\n",
        "        # restore the children of the current node\n",
        "        if err > cur_error or decision_tree_root.count_node() <= 5:\n",
        "            self.restore(temp_attr, temp_left, temp_right)\n",
        "\n",
        "\n",
        "\n",
        "def construct_tree_gini(samples, current_height, max_height, attr_list):\n",
        "    '''\n",
        "    This function is the main function the handles the construction \n",
        "    of the entire decision tree handling all the steps. This function \n",
        "    implements the ID3 algorithm with the help of the  functions \n",
        "    '''\n",
        "\n",
        "    # if the max height is reached then return\n",
        "    if current_height == max_height or len(samples) == 0:\n",
        "        return None\n",
        "\n",
        "    # if we have one data only then store it in the node and\n",
        "    # consider this as the prediction alue for this node also\n",
        "    if len(samples) == 1:\n",
        "        return node('y', samples[0]['y'], samples[0]['y'], 0)\n",
        "\n",
        "    # select the best attribute to be selected for this node\n",
        "    # with the help of the functions\n",
        "    attr, split, mse = good_attr_gini(samples, attr_list)\n",
        "    samples1, samples2, mean = [], [], 0\n",
        "\n",
        "    for i in samples:\n",
        "        mean += i['y']\n",
        "        if i[attr] <= split:\n",
        "            samples1.append(i)\n",
        "        else:\n",
        "            samples2.append(i)\n",
        "\n",
        "    # consider the mean as the prediction for the current node\n",
        "    mean /= len(samples)\n",
        "\n",
        "    # recursively build the left and the right children of\n",
        "    # the current node and the return this node as the head\n",
        "    head = node(attr, split, mean, mse)\n",
        "    head.left = construct_tree_gini(\n",
        "        samples1, current_height+1, max_height, attr_list)\n",
        "    head.right = construct_tree_gini(\n",
        "        samples2, current_height+1, max_height, attr_list)\n",
        "    if head.left == None and head.right == None:\n",
        "        head.attr = 'y'\n",
        "        head.split = head.mean\n",
        "\n",
        "    return head\n",
        "\n",
        "def construct_tree_infogain(samples, current_height, max_height, attr_list):\n",
        "    '''\n",
        "    This function is the main function the handles the construction \n",
        "    of the entire decision tree handling all the steps. This function \n",
        "    implements the ID3 algorithm with the help of the  functions \n",
        "    '''\n",
        "\n",
        "    # if the max height is reached then return\n",
        "    if current_height == max_height or len(samples) == 0:\n",
        "        return None\n",
        "\n",
        "    # if we have one data only then store it in the node and\n",
        "    # consider this as the prediction alue for this node also\n",
        "    if len(samples) == 1:\n",
        "        return node('y', samples[0]['y'], samples[0]['y'], 0)\n",
        "\n",
        "    # select the best attribute to be selected for this node\n",
        "    # with the help of the functions\n",
        "    attr, split, mse = good_attr_infogain(samples, attr_list)\n",
        "    samples1, samples2, mean = [], [], 0\n",
        "\n",
        "    for i in samples:\n",
        "        mean += i['y']\n",
        "        if i[attr] <= split:\n",
        "            samples1.append(i)\n",
        "        else:\n",
        "            samples2.append(i)\n",
        "\n",
        "    # consider the mean as the prediction for the current node\n",
        "    mean /= len(samples)\n",
        "\n",
        "    # recursively build the left and the right children of\n",
        "    # the current node and the return this node as the head\n",
        "    head = node(attr, split, mean, mse)\n",
        "    head.left = construct_tree_infogain(\n",
        "        samples1, current_height+1, max_height, attr_list)\n",
        "    head.right = construct_tree_infogain(\n",
        "        samples2, current_height+1, max_height, attr_list)\n",
        "    if head.left == None and head.right == None:\n",
        "        head.attr = 'y'\n",
        "        head.split = head.mean\n",
        "\n",
        "    return head\n",
        "\n",
        "\n",
        "def predict_one(decision_tree, data):\n",
        "    '''\n",
        "    This function is used for prediction of a singe sample\n",
        "    In this we do a depth first search through the decision\n",
        "    tree with the help of the attribute stored in the nodes \n",
        "    '''\n",
        "\n",
        "    # if the leaf node is reached thenreturn the prediction\n",
        "    # stored at this node\n",
        "    if decision_tree==None:\n",
        "      pass\n",
        "    elif decision_tree.left == None and decision_tree.right == None:\n",
        "        return decision_tree.mean\n",
        "\n",
        "    # based on the decision either recurse to the left\n",
        "    # or the right half until the leaf node is reached\n",
        "    if decision_tree==None:\n",
        "      pass\n",
        "    elif data[decision_tree.attr] <= decision_tree.split:\n",
        "        return predict_one(decision_tree.left, data)\n",
        "    else :\n",
        "      return predict_one(decision_tree.right, data)\n",
        "    return False\n",
        "\n",
        "\n",
        "def predict(decision_tree, data):\n",
        "    '''\n",
        "    This function is used for predistion of a multiple samples\n",
        "    In this function we make use of the function predict_one \n",
        "    for each item in the data list\n",
        "    '''\n",
        "\n",
        "    mse, preds = 0, []\n",
        "    for i in data:\n",
        "\n",
        "        # make prediction for the current data point\n",
        "        val = predict_one(decision_tree, i)\n",
        "        # insert the prediction in the prediction array\n",
        "        preds.append(val)\n",
        "        mse += (val-i['y'])**2\n",
        "\n",
        "    # calculate the average error\n",
        "    mse = mse/len(data)\n",
        "    return mse, preds"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LoYwOLlFfDB"
      },
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from graphviz import Digraph\n"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCvJibyWFmpY"
      },
      "source": [
        "def to_construct(file):\n",
        "    '''\n",
        "    Converts bupa data to new data file which is constructed based on the condition drinks >=5\n",
        "    '''\n",
        "    with open(\"bupa.data\",mode='r') as data_file:\n",
        "        data_reader= csv.DictReader(data_file)\n",
        "        line=0\n",
        "        with open('newbupa.data',mode='w') as newdata_file:\n",
        "          newdata_writer = csv.writer(newdata_file,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "          for row in data_reader :\n",
        "            if(line==0):\n",
        "              newdata_writer.writerow([\"mcv\",\"alkphos\",\"sgpt\",\"sgot\",\"gammagt\",'y'])\n",
        "              line=line+1\n",
        "            if(float(row[\"drinks\"])>=5) :\n",
        "              newdata_writer.writerow([row[\"mcv\"],row[\"alkphos\"],row[\"sgpt\"],row[\"sgot\"],row[\"gammagt\"],'1'])\n",
        "            else :\n",
        "              newdata_writer.writerow([row[\"mcv\"],row[\"alkphos\"],row[\"sgpt\"],row[\"sgot\"],row[\"gammagt\"],'0'])\n",
        "            line=line+1\n",
        "    return newdata_file"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYXGwu2_Koaw",
        "outputId": "053c3ad4-becc-402a-95f4-b4502defa735"
      },
      "source": [
        "to_construct('bupa.data')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='newbupa.data' mode='w' encoding='UTF-8'>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFoWIRoFFrqd"
      },
      "source": [
        "def read_data(newdata_file):\n",
        "    '''\n",
        "     A pandas dataframe consisting of the data read from the 'dupa.data'\n",
        "    '''\n",
        "    df = pd.read_csv(newdata_file).drop(index=0)\n",
        "    return df"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXVd3yTlLGaa"
      },
      "source": [
        "df=read_data('newbupa.data')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSbkLJKkFxZ9"
      },
      "source": [
        "def build_data(df):\n",
        "    '''\n",
        "    Converts the data from the pandas data freame format to array of dictionary objects\n",
        "    '''\n",
        "    data = []\n",
        "    for i in range(1, len(df['mcv'])+1):\n",
        "        data.append(\n",
        "            {\n",
        "                'mcv':          df['mcv'][i],\n",
        "                'alkphos':      df['alkphos'][i],\n",
        "                'sgpt':         df['sgpt'][i],\n",
        "                'sgot':         df['sgot'][i],\n",
        "                'gammagt':      df['gammagt'][i],\n",
        "                'y' :           df['y'][i]\n",
        "            }\n",
        "        )\n",
        "    return data"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "disK_w14FzZj"
      },
      "source": [
        "def train_test_split(df):\n",
        "    '''\n",
        "    This function will first convert the pandas dataframe into array of dictionary objects then splits the data into \n",
        "    X_train and X_test using an 80-20 split for training : test\n",
        "    '''\n",
        "    data = build_data(df)\n",
        "    random.shuffle(data)\n",
        "    X_train, X_test = data[:int(0.6*len(data))], data[int(0.8*len(data)):]\n",
        "    return X_train, X_test"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU-mZuIYMGgx"
      },
      "source": [
        "def train_valid_split(data):\n",
        "    '''\n",
        "    data: This function is to split the input data in to training set and validation set. The following function \n",
        "    makes use of the K-fold cross validation wher the data is divided into 4 parts and three parts is used for \n",
        "    training and one art for validation \n",
        "    '''\n",
        "\n",
        "    random.shuffle(data)\n",
        "    X_train, X_valid = data[:int(\n",
        "        0.75*len(data))], data[int(0.75*len(data)):]\n",
        "    return X_train, X_valid\n"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EJBjKT4F3xo"
      },
      "source": [
        "\n",
        "def entropy(target_col):\n",
        "    \"\"\"\n",
        "    Calculate the entropy of a dataset.\n",
        "    The only parameter of this function is the target_col parameter which specifies the target column\n",
        "    \"\"\"\n",
        "    elements,counts = np.unique(target_col,return_counts = True)\n",
        "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
        "    return entropy\n"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T6OJSoLF7xk"
      },
      "source": [
        "def information_gain(data,target_name=\"class\"):\n",
        "    \"\"\"\n",
        "    Calculate the information gain of a dataset. This function takes three parameters:\n",
        "    1. data = The dataset for whose feature the IG should be calculated\n",
        "    2. target_name = the name of the target feature. The default for this example is \"class\"\n",
        "    \"\"\"    \n",
        "    #Calculate the entropy of the total dataset\n",
        "    total_entropy = entropy(data)\n",
        "    \n",
        "    ##Calculate the entropy of the dataset\n",
        "    \n",
        "    #Calculate the values and the corresponding counts for the split attribute \n",
        "    vals,counts= np.unique(data,return_counts=True)\n",
        "    \n",
        "    #Calculate the weighted entropy\n",
        "    Weighted_Entropy = np.sum([((counts[i]/np.sum(counts))*entropy(data==vals[i])) for i in range(len(vals))])\n",
        "    \n",
        "    #Calculate the information gain\n",
        "    Information_Gain = total_entropy - Weighted_Entropy\n",
        "    return Information_Gain\n"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlJrasXdGCAJ"
      },
      "source": [
        "def good_attr_infogain(data, attr_list):\n",
        "    '''\n",
        "    This function is a helper function which helps to select which attribute will be the best if selected at this level\n",
        "    for splitting. the measure used in this method is variance \n",
        "    '''\n",
        "\n",
        "    best, best_attr, split, mse = -1, '', 0, 0\n",
        "\n",
        "    # shuffle the list to get better variation\n",
        "    # in selection of the attributes\n",
        "    random.shuffle(attr_list)\n",
        "\n",
        "    # for each attribute find the best change in variance\n",
        "    for attr in attr_list:\n",
        "\n",
        "        # create a list of data for the current attribute\n",
        "        attr_data = [{\n",
        "            'val': i[attr],\n",
        "            'y': i['y']\n",
        "        } for i in data]\n",
        "\n",
        "        # define the local variables\n",
        "        local_best, local_val = -1, 0\n",
        "\n",
        "        # sort the data for easy manipulation\n",
        "        data_left, data_right = [], sorted([i['y'] for i in attr_data])\n",
        "        data_var, data_len = information_gain(data_right), len(attr_data)\n",
        "        left_len, right_len = 0, data_len\n",
        "\n",
        "        # iterate through all the mid points of conecutive data points\n",
        "        # to select the best split for the attribute\n",
        "        for i in range(1, len(attr_data)):\n",
        "            mid = (attr_data[i-1]['val'] + attr_data[i]['val']) // 2\n",
        "            data_left.append(data_right.pop(0))\n",
        "            left_len, right_len = left_len+1, right_len-1\n",
        "\n",
        "        left_var = information_gain(data_left)\n",
        "        right_var = information_gain(data_right)\n",
        "\n",
        "        # calculate the current change in variance\n",
        "        gain = data_var - (left_len/data_len*left_var + right_len/data_len*right_var)\n",
        "\n",
        "        # if the change is more than any change observed\n",
        "        # till now then select this split as the best\n",
        "        if gain > local_best:\n",
        "            local_best = gain\n",
        "            local_val = mid\n",
        "\n",
        "    # check if the current attribute gives the best\n",
        "    # change in the variance measure, if so then\n",
        "    # select this attribute as the best measure\n",
        "    if local_best > best:\n",
        "        best = local_best\n",
        "        best_attr = attr\n",
        "        split = local_val\n",
        "        mse = data_var\n",
        "\n",
        "    return best_attr, split, mse"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJo1m7vQR0wQ"
      },
      "source": [
        "def count_values(data):\n",
        "    #will return a dictionary with species values as key and frequency as values\n",
        "    count={}\n",
        "    #takes whole dataset in as argument\n",
        "    for row in data:\n",
        "        #traverse on each datapoint\n",
        "        label=row\n",
        "        #labels are in the last column\n",
        "        #if label is not even once come initialise it\n",
        "        if label not in count:\n",
        "            count[label]=0\n",
        "        #increase the count of present label by 1\n",
        "        count[label]+=1\n",
        "    return count "
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJpNFyUhGIRl"
      },
      "source": [
        "\n",
        "def gini_index(data):\n",
        "    #stores dictionary of frequency of labels\n",
        "    count=count_values(data)\n",
        "    #initialise impurity as 1\n",
        "    impurity=1\n",
        "    for label in count:\n",
        "        #probablity of a unique label\n",
        "        probab_of_label=count[label]/float(len(data))\n",
        "        #calculation gini impurity acc to formula\n",
        "        impurity-=probab_of_label**2\n",
        "    return impurity"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9Ugu4vAGMlL"
      },
      "source": [
        "def good_attr_gini(data, attr_list):\n",
        "    '''\n",
        "    This function is a helper function which helps to select which attribute will be the best if selected at this level\n",
        "    for splitting. the measure used in this method is variance \n",
        "    '''\n",
        "\n",
        "    best, best_attr, split, mse = -1, '', 0, 0\n",
        "\n",
        "    # shuffle the list to get better variation\n",
        "    # in selection of the attributes\n",
        "    random.shuffle(attr_list)\n",
        "\n",
        "    # for each attribute find the best change in variance\n",
        "    for attr in attr_list:\n",
        "\n",
        "        # create a list of data for the current attribute\n",
        "        attr_data = [{\n",
        "            'val': i[attr],\n",
        "            'y': i['y']\n",
        "        } for i in data]\n",
        "\n",
        "        # define the local variables\n",
        "        local_best, local_val = -1, 0\n",
        "\n",
        "        # sort the data for easy manipulation\n",
        "        data_left, data_right = [], sorted([i['y'] for i in attr_data])\n",
        "        data_var, data_len = gini_index(data_right), len(attr_data)\n",
        "        left_len, right_len = 0, data_len\n",
        "\n",
        "        # iterate through all the mid points of conecutive data points\n",
        "        # to select the best split for the attribute\n",
        "        for i in range(1, len(attr_data)):\n",
        "            mid = (attr_data[i-1]['val'] + attr_data[i]['val']) // 2\n",
        "            data_left.append(data_right.pop(0))\n",
        "            left_len, right_len = left_len+1, right_len-1\n",
        "\n",
        "        left_var = gini_index(data_left)\n",
        "        right_var = gini_index(data_right)\n",
        "\n",
        "        # calculate the current change in variance\n",
        "        gain = data_var - (left_len/data_len*left_var + right_len/data_len*right_var)\n",
        "\n",
        "        # if the change is more than any change observed\n",
        "        # till now then select this split as the best\n",
        "        if gain > local_best:\n",
        "            local_best = gain\n",
        "            local_val = mid\n",
        "\n",
        "    # check if the current attribute gives the best\n",
        "    # change in the variance measure, if so then\n",
        "    # select this attribute as the best measure\n",
        "    if local_best > best:\n",
        "        best = local_best\n",
        "        best_attr = attr\n",
        "        split = local_val\n",
        "        mse = data_var\n",
        "\n",
        "    return best_attr, split, mse"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBPxSJ0GRBq"
      },
      "source": [
        "def is_leaf(node):\n",
        "    '''\n",
        "    this function checks whether the currnent node is a leaf node\n",
        "    '''\n",
        "\n",
        "    is_leaf = (node.left == None and node.right == None)\n",
        "    return is_leaf\n",
        "\n",
        "\n",
        "def get(node):\n",
        "    '''\n",
        "    this function returns a formatted string which will be used for printing the parameters inside the node when the graph is crated using graphviz\n",
        "    '''\n",
        "    if not is_leaf(node):\n",
        "        return \"{} <= {}\\nmse = {}\\nmean = {}\".format(node.attr, node.split, node.mse, node.mean)\n",
        "    return \"{} == {}\\nmse = {}\\nmean = {}\".format(node.attr, node.split, node.mse, node.mean)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb-hKviuGVyh"
      },
      "source": [
        "def print_decision_tree(dtree):\n",
        "    '''\n",
        "    this function prints the ddecision tree graph so created and saves the output in the a pdf file \n",
        "    '''\n",
        "\n",
        "    # create a new Digraph\n",
        "    f = Digraph('Decision Tree', filename='decision_tree.gv')\n",
        "    f.attr(rankdir='LR', size='1000,500')\n",
        "\n",
        "    # border of the nodes is set to rectangle shape\n",
        "    f.attr('node', shape='rectangle')\n",
        "\n",
        "    # Do a breadth first search and add all the edges in the output graph\n",
        "    q = [dtree]  # queue for the bradth first search\n",
        "    while len(q) > 0:\n",
        "        node = q.pop(0)\n",
        "        if node.left != None:\n",
        "            f.edge(get(node), get(node.left), label='True')\n",
        "        if node.right != None:\n",
        "            f.edge(get(node), get(node.right), label='False')\n",
        "\n",
        "        if node.left != None:\n",
        "            q.append(node.left)\n",
        "        if node.right != None:\n",
        "            q.append(node.right)\n",
        "\n",
        "    # save file name :  decision_tree.gv.pdf\n",
        "    f.render('./decision_tree.gv', view=True)\n"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHWP2l3SGgMP"
      },
      "source": [
        "def r2_score(Y, Y_hat):\n",
        "    '''\n",
        "    this function calculates the r2 score  of the decision tree over the input dataset\n",
        "    '''\n",
        "    ssr, sst = 0, 0\n",
        "    Y_bar = sum(Y)/len(Y)\n",
        "    for i, val in enumerate(Y):\n",
        "        ssr += (val-Y_hat[i])**2\n",
        "        sst += (val-Y_bar)**2\n",
        "\n",
        "    if sst==0 : sst = 10**-20\n",
        "    score = 1-ssr/sst\n",
        "    return score\n",
        "\n",
        "\n",
        "def get_accuracy(decision_tree, X_data):\n",
        "    '''\n",
        "    this function returns accuracy of the decision tree over the dataset as measured by the r2_score measure \n",
        "    '''\n",
        "    _, preds = predict(decision_tree, X_data)\n",
        "    data = []\n",
        "    for i in X_data:\n",
        "        data.append(i['y'])\n",
        "    acc = r2_score(data, preds)\n",
        "    return acc"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncfpqy9VGkj0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78-p6pZwGkoV"
      },
      "source": [
        "import argparse\n",
        "import time\n",
        "import random\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KywVqLH-GrGF"
      },
      "source": [
        "def randomize_select_best_tree_gini(data, max_height, X_test):\n",
        "\n",
        "    # print(max_height, len(data), len(X_test))\n",
        "    if max_height == -1:\n",
        "        max_height = 300\n",
        "\n",
        "    attributes = [\"mcv\",\"alkphos\",\"sgpt\",\"sgot\",\"gammagt\",\"y\"]\n",
        "\n",
        "    # set the local variables\n",
        "    least_mse, tree, mse_avg, acc_avg = 10**18, None, 0, 0\n",
        "    train, valid = None, None\n",
        "\n",
        "    for _ in range(10):\n",
        "\n",
        "        X_train, X_valid = train_valid_split(data) \n",
        "        decision_tree = construct_tree_gini(X_train, 0, max_height, attributes)\n",
        "\n",
        "        test_mse, _ = predict(decision_tree, X_test)\n",
        "        test_acc = get_accuracy(decision_tree, X_test)\n",
        "\n",
        "        if test_mse < least_mse:\n",
        "            least_mse = test_mse\n",
        "            mse_avg += test_mse\n",
        "            acc_avg += test_acc\n",
        "            tree = decision_tree\n",
        "            train = X_train\n",
        "            valid = X_valid\n",
        "\n",
        "    mse_avg /= 10\n",
        "    acc_avg /= 10\n",
        "    return tree, train, valid, mse_avg, acc_avg\n",
        "\n",
        "def randomize_select_best_tree_infogain(data, max_height, X_test):\n",
        "\n",
        "    # print(max_height, len(data), len(X_test))\n",
        "    if max_height == -1:\n",
        "        max_height = 300\n",
        "\n",
        "    attributes = [\"mcv\",\"alkphos\",\"sgpt\",\"sgot\",\"gammagt\",\"y\"]\n",
        "\n",
        "    # set the local variables\n",
        "    least_mse, tree, mse_avg, acc_avg = 10**18, None, 0, 0\n",
        "    train, valid = None, None\n",
        "\n",
        "    for _ in range(10):\n",
        "\n",
        "        X_train, X_valid = train_valid_split(data) \n",
        "        decision_tree = construct_tree_infogain(X_train, 0, max_height, attributes)\n",
        "\n",
        "        test_mse, _ = predict(decision_tree, X_test)\n",
        "        test_acc = get_accuracy(decision_tree, X_test)\n",
        "\n",
        "        if test_mse < least_mse:\n",
        "            least_mse = test_mse\n",
        "            mse_avg += test_mse\n",
        "            acc_avg += test_acc\n",
        "            tree = decision_tree\n",
        "            train = X_train\n",
        "            valid = X_valid\n",
        "\n",
        "    mse_avg /= 10\n",
        "    acc_avg /= 10\n",
        "    return tree, train, valid, mse_avg, acc_avg"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aVfAJ1vGx_B"
      },
      "source": [
        "def randomize_select_best_height_tree_gini(train, X_test):\n",
        "    mse, height, cur_mse = [], [], 10**18\n",
        "    decision_tree, ht = None, -1\n",
        "    for h in range(1, 50):\n",
        "        print(\"[---- Height {} -----] \".format(h), end = '')\n",
        "        decision_tree_sample, temp_train, temp_valid, _, _ = randomize_select_best_tree_gini(train, h, test)\n",
        "        mse_test = predict(decision_tree_sample, test)[0]\n",
        "        if mse_test < cur_mse and h > 4: \n",
        "            decision_tree = decision_tree_sample\n",
        "            cur_mse = mse_test\n",
        "            X_train = temp_train\n",
        "            X_valid = temp_valid\n",
        "            ht = h\n",
        "        \n",
        "        data_print(decision_tree_sample, train, X_test, valid)\n",
        "        mse.append(mse_test)\n",
        "        height.append(h)\n",
        "\n",
        "    plt.title(\"test-mse vs height\")\n",
        "    plt.ylabel(\"test-mse\")\n",
        "    plt.xlabel(\"height\")\n",
        "    plt.plot(height, mse)\n",
        "\n",
        "    return decision_tree, X_train, X_valid, ht\n",
        "\n",
        "\n",
        "def randomize_select_best_height_tree_infogain(train, X_test):\n",
        "    mse, height, cur_mse = [], [], 10**18\n",
        "    decision_tree, ht = None, -1\n",
        "    for h in range(1, 50):\n",
        "        print(\"[---- Height {} -----] \".format(h), end = '')\n",
        "        decision_tree_sample, temp_train, temp_valid, _, _ = randomize_select_best_tree_infogain(train, h, test)\n",
        "        mse_test = predict(decision_tree_sample, test)[0]\n",
        "        if mse_test < cur_mse and h > 4: \n",
        "            decision_tree = decision_tree_sample\n",
        "            cur_mse = mse_test\n",
        "            X_train = temp_train\n",
        "            X_valid = temp_valid\n",
        "            ht = h\n",
        "        \n",
        "        data_print(decision_tree_sample, train, X_test, valid)\n",
        "        mse.append(mse_test)\n",
        "        height.append(h)\n",
        "\n",
        "    plt.title(\"test-mse vs height\")\n",
        "    plt.ylabel(\"test-mse\")\n",
        "    plt.xlabel(\"height\")\n",
        "    plt.plot(height, mse)\n",
        "\n",
        "    return decision_tree, X_train, X_valid, ht\n",
        "\n",
        "\n"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pT3eI-mKG3Mz"
      },
      "source": [
        "def data_print(tree, train, test, valid):\n",
        "    print(\"train acc: {}, train mse: {}\".format(round(get_accuracy(tree, train)*100,2), round(predict(tree, train)[0],2)), end=', ')\n",
        "\n",
        "    # print(\"valid acc: {}, valid mse: {}\".format(\n",
        "    #     round(get_accuracy(tree, valid)*100, 2), round(predict(tree, valid)[0], 2)), end=', ')\n",
        "\n",
        "    print(\"test acc: {}, test mse: {}\".format(round(get_accuracy(tree, test)*100, 2), round(predict(tree, test)[0], 2)))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsJmTNLdIYkV"
      },
      "source": [
        "import sys\n",
        "sys.argv=['']\n",
        "del sys\n"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHTD6ftqIb13"
      },
      "source": [
        "random.seed(100000)\n",
        "start = time.time()\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--height\", help=\"maximum height of decision tree for Q1\", type=int)\n",
        "args = parser.parse_args()\n",
        "ht = -1\n",
        "if args.height:\n",
        "    ht = args.height"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCh1-RKKK4fK",
        "outputId": "af3ba1ed-ce87-4a25-aa3e-9166fd34ca78"
      },
      "source": [
        "print(\"Time elapsed  =  {} ms\".format(time.time()-start))\n",
        "print(\"\\n ============= DATA READ ============ \\n\\n\")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time elapsed  =  4.53882360458374 ms\n",
            "\n",
            " ============= DATA READ ============ \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPUr6N9ELd8h",
        "outputId": "525e6d0f-1fcc-4eca-b8e1-3e88d8d0b862"
      },
      "source": [
        "train, test = train_test_split(df)\n",
        "print(\"============= TRAIN TEST SPLIT COMPLETE ============\\n\")\n",
        "print(\"train data size: {}, test data size = {} \\n\\n\".format(len(train), len(test)))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============= TRAIN TEST SPLIT COMPLETE ============\n",
            "\n",
            "train data size: 206, test data size = 69 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tGsfPqlbgIQ"
      },
      "source": [
        "GINI IMPURITY\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QRXBezRLjIp",
        "outputId": "51a00200-86e0-4a43-f8c2-ec36612d7f65"
      },
      "source": [
        "print(\"============== SOLVING Q1 ==============\\n\")\n",
        "print(\"height selected: {}\".format(ht if ht != -1 else \"Full Tree\"))\n",
        "print(\"\\n========= TRAINING STARTED =========\\n\")\n",
        "\n",
        "X_train = train\n",
        "start = time.time()\n",
        "tree, train, valid, mse_avg, acc_avg = randomize_select_best_tree_gini(train, ht, test)\n",
        "print(\"Time elapsed  =  {} ms\".format(time.time()-start))\n",
        "print(\"\\n ============= TRAINING FINISHED ============ \\n\")\n",
        "print(\"Average Test Accuracy: {}\\n\".format(acc_avg * 100))\n",
        "print(\"Average Test MSE: {}\\n\".format(mse_avg))\n",
        "\n",
        "data_print(tree, train, test, valid)\n",
        "train = X_train\n",
        "print(\"\\n============== SOLVED Q1 ==============\\n\")"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============== SOLVING Q1 ==============\n",
            "\n",
            "height selected: Full Tree\n",
            "\n",
            "========= TRAINING STARTED =========\n",
            "\n",
            "Time elapsed  =  0.3268575668334961 ms\n",
            "\n",
            " ============= TRAINING FINISHED ============ \n",
            "\n",
            "Average Test Accuracy: 18.030612244897963\n",
            "\n",
            "Average Test MSE: 0.02463768115942029\n",
            "\n",
            "train acc: 100.0, train mse: 0.0, test acc: 78.88, test mse: 0.04\n",
            "\n",
            "============== SOLVED Q1 ==============\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U9PnZoMUaPYL",
        "outputId": "c4f5a24d-6a88-4b30-c386-518eae16d180"
      },
      "source": [
        "print(\"\\n============== SOLVING Q3 ==============\\n\")\n",
        "print(\"\\n========= TRAINING STARTED =========\\n\")\n",
        "\n",
        "start = time.time()\n",
        "tree, train, valid, ht = randomize_select_best_height_tree_gini(train, test)\n",
        "print(\"Time elapsed  =  {} ms\".format(time.time()-start))\n",
        "print(\"\\n ============= TRAINING FINISHED ============ \\n\")\n",
        "print(\"BEST TREE: height = {}\".format(ht))\n",
        "data_print(tree, train, test, valid)\n",
        "\n",
        "print(\"\\n============== SOLVED Q3 ==============\\n\")"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============== SOLVING Q3 ==============\n",
            "\n",
            "\n",
            "========= TRAINING STARTED =========\n",
            "\n",
            "[---- Height 1 -----] train acc: -0.89, train mse: 0.22, test acc: -0.01, test mse: 0.21\n",
            "[---- Height 2 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 3 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 4 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 5 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 6 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 7 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 8 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 9 -----] train acc: 100.0, train mse: 0.0, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 10 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 11 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 12 -----] train acc: 97.8, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 13 -----] train acc: 95.61, train mse: 0.01, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 14 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 15 -----] train acc: 97.8, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 16 -----] train acc: 97.8, train mse: 0.0, test acc: 78.88, test mse: 0.04\n",
            "[---- Height 17 -----] train acc: 93.41, train mse: 0.01, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 18 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 19 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 20 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 21 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 22 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 23 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 24 -----] train acc: 89.02, train mse: 0.02, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 25 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 26 -----] train acc: 100.0, train mse: 0.0, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 27 -----] train acc: 91.22, train mse: 0.02, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 28 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 29 -----] train acc: 97.8, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 30 -----] train acc: 97.8, train mse: 0.0, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 31 -----] train acc: 100.0, train mse: 0.0, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 32 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 33 -----] train acc: 97.8, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 34 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 35 -----] train acc: 100.0, train mse: 0.0, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 36 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 37 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 38 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 39 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 40 -----] train acc: 95.61, train mse: 0.01, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 41 -----] train acc: 93.41, train mse: 0.01, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 42 -----] train acc: 97.8, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 43 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 44 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 45 -----] train acc: 95.61, train mse: 0.01, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 46 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 47 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 48 -----] train acc: 93.41, train mse: 0.01, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 49 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "Time elapsed  =  10.83008861541748 ms\n",
            "\n",
            " ============= TRAINING FINISHED ============ \n",
            "\n",
            "BEST TREE: height = 5\n",
            "train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "\n",
            "============== SOLVED Q3 ==============\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXFcH00yavu0",
        "outputId": "c777a081-47bb-4830-86f5-9ade0f03846c"
      },
      "source": [
        "print(\"\\n============== SOLVING Q4 ==============\\n\")\n",
        "print(\"[==== BEFORE PRUNING ====] Valid acc: {}, Valid mse: {}, number of nodes = {}\".format(get_accuracy(tree, valid)*100, predict(tree, valid)[0], tree.count_node()))\n",
        "tree.prune(tree, predict(tree, valid)[0], valid)\n",
        "print(\"[==== AFTER PRUNING ====] Valid acc: {}, Valid mse: {}, number of nodes = {}\\n\".format(get_accuracy(tree, valid)*100, predict(tree, valid)[0], tree.count_node()))\n",
        "data_print(tree, train, test, valid)\n",
        "\n",
        "print(\"\\n============== SOLVED Q4 ==============\\n\")\n"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============== SOLVING Q4 ==============\n",
            "\n",
            "[==== BEFORE PRUNING ====] Valid acc: 100.0, Valid mse: 0.0, number of nodes = 19\n",
            "[==== AFTER PRUNING ====] Valid acc: 100.0, Valid mse: 0.0, number of nodes = 7\n",
            "\n",
            "train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "\n",
            "============== SOLVED Q4 ==============\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxK9O6yBa90y",
        "outputId": "14fe0e91-e7e1-469a-c13b-a998adc23d84"
      },
      "source": [
        "print(\"\\n============== SOLVING Q5 ==============\\n\")\n",
        "print('\\n SAVING =====> \\n')\n",
        "print_decision_tree( tree )\n",
        "print('The image of the graph is saved as [ decision_tree.gv.pdf ]')\n",
        "print(\"\\n============== SOLVED Q5 ==============\\n\")"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============== SOLVING Q5 ==============\n",
            "\n",
            "\n",
            " SAVING =====> \n",
            "\n",
            "The image of the graph is saved as [ decision_tree.gv.pdf ]\n",
            "\n",
            "============== SOLVED Q5 ==============\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wC-hq0tGfS98"
      },
      "source": [
        "Information Gain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4B8j9o2jfR4Z",
        "outputId": "e2122760-ac48-4cfa-8ed6-9dae85185d90"
      },
      "source": [
        "print(\"\\n============== SOLVING Q3 ==============\\n\")\n",
        "print(\"\\n========= TRAINING STARTED =========\\n\")\n",
        "\n",
        "start = time.time()\n",
        "tree, train, valid, ht = randomize_select_best_height_tree_infogain(train, test)\n",
        "print(\"Time elapsed  =  {} ms\".format(time.time()-start))\n",
        "print(\"\\n ============= TRAINING FINISHED ============ \\n\")\n",
        "print(\"BEST TREE: height = {}\".format(ht))\n",
        "data_print(tree, train, test, valid)\n",
        "\n",
        "print(\"\\n============== SOLVED Q3 ==============\\n\")"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============== SOLVING Q3 ==============\n",
            "\n",
            "\n",
            "========= TRAINING STARTED =========\n",
            "\n",
            "[---- Height 1 -----] train acc: -0.45, train mse: 0.22, test acc: -0.0, test mse: 0.21\n",
            "[---- Height 2 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 3 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 4 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 5 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 6 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 7 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 8 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 9 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 10 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 11 -----] train acc: 97.01, train mse: 0.01, test acc: 85.92, test mse: 0.03\n",
            "[---- Height 12 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 13 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 14 -----] train acc: 97.01, train mse: 0.01, test acc: 85.92, test mse: 0.03\n",
            "[---- Height 15 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 16 -----] train acc: 94.01, train mse: 0.01, test acc: 57.76, test mse: 0.09\n",
            "[---- Height 17 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 18 -----] train acc: 94.01, train mse: 0.01, test acc: 85.92, test mse: 0.03\n",
            "[---- Height 19 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 20 -----] train acc: 79.05, train mse: 0.05, test acc: 57.76, test mse: 0.09\n",
            "[---- Height 21 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 22 -----] train acc: 88.03, train mse: 0.03, test acc: 36.63, test mse: 0.13\n",
            "[---- Height 23 -----] train acc: 100.0, train mse: 0.0, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 24 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 25 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 26 -----] train acc: 94.01, train mse: 0.01, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 27 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 28 -----] train acc: 100.0, train mse: 0.0, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 29 -----] train acc: 85.03, train mse: 0.03, test acc: 71.84, test mse: 0.06\n",
            "[---- Height 30 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 31 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 32 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 33 -----] train acc: 94.01, train mse: 0.01, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 34 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 35 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 36 -----] train acc: 100.0, train mse: 0.0, test acc: 92.96, test mse: 0.01\n",
            "[---- Height 37 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 38 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 39 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 40 -----] train acc: 97.01, train mse: 0.01, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 41 -----] train acc: 97.01, train mse: 0.01, test acc: 85.92, test mse: 0.03\n",
            "[---- Height 42 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 43 -----] train acc: 97.01, train mse: 0.01, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 44 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 45 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 46 -----] train acc: 94.01, train mse: 0.01, test acc: 85.92, test mse: 0.03\n",
            "[---- Height 47 -----] train acc: 97.01, train mse: 0.01, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 48 -----] train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "[---- Height 49 -----] train acc: 94.01, train mse: 0.01, test acc: 85.92, test mse: 0.03\n",
            "Time elapsed  =  234.81918573379517 ms\n",
            "\n",
            " ============= TRAINING FINISHED ============ \n",
            "\n",
            "BEST TREE: height = 5\n",
            "train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "\n",
            "============== SOLVED Q3 ==============\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB2JqtN_peD3",
        "outputId": "41c39602-3bb9-4d2b-80a0-4d35efce29e6"
      },
      "source": [
        "print(\"\\n============== SOLVING Q4 ==============\\n\")\n",
        "print(\"[==== BEFORE PRUNING ====] Valid acc: {}, Valid mse: {}, number of nodes = {}\".format(get_accuracy(tree, valid)*100, predict(tree, valid)[0], tree.count_node()))\n",
        "tree.prune(tree, predict(tree, valid)[0], valid)\n",
        "print(\"[==== AFTER PRUNING ====] Valid acc: {}, Valid mse: {}, number of nodes = {}\\n\".format(get_accuracy(tree, valid)*100, predict(tree, valid)[0], tree.count_node()))\n",
        "data_print(tree, train, test, valid)\n",
        "\n",
        "print(\"\\n============== SOLVED Q4 ==============\\n\")"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============== SOLVING Q4 ==============\n",
            "\n",
            "[==== BEFORE PRUNING ====] Valid acc: 100.0, Valid mse: 0.0, number of nodes = 25\n",
            "[==== AFTER PRUNING ====] Valid acc: 100.0, Valid mse: 0.0, number of nodes = 7\n",
            "\n",
            "train acc: 100.0, train mse: 0.0, test acc: 100.0, test mse: 0.0\n",
            "\n",
            "============== SOLVED Q4 ==============\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swZlMspdphMp",
        "outputId": "f5ea243e-7421-4dc2-d44a-a4f4932a3b7c"
      },
      "source": [
        "print(\"\\n============== SOLVING Q5 ==============\\n\")\n",
        "print('\\n SAVING =====> \\n')\n",
        "print_decision_tree( tree )\n",
        "print('The image of the graph is saved as [ decision_tree.gv.pdf ]')\n",
        "print(\"\\n============== SOLVED Q5 ==============\\n\")"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============== SOLVING Q5 ==============\n",
            "\n",
            "\n",
            " SAVING =====> \n",
            "\n",
            "The image of the graph is saved as [ decision_tree.gv.pdf ]\n",
            "\n",
            "============== SOLVED Q5 ==============\n",
            "\n"
          ]
        }
      ]
    }
  ]
}